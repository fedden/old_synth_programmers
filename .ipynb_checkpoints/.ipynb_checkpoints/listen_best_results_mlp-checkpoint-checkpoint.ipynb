{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded Dexed\n",
      "\n",
      "\n",
      "Started generating data for normaliser's fitting, this may take some time...\n",
      "\n",
      "\n",
      "Finished generating!\n",
      "\n",
      "\n",
      "Finished fitting!\n",
      "\n",
      "\n",
      "INFO:tensorflow:Summary name Weights Out is illegal; using Weights_Out instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "INFO:tensorflow:Summary name Weights Out is illegal; using Weights_Out instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "\n",
      "\n",
      "      In order of most to least similar predictions compared to the actual parameters:\n",
      "\n",
      "      Index   Total abs\n",
      "       _______________\n",
      "0000)  0039 : 35.08513\n",
      "0001)  0087 : 35.25499\n",
      "0002)  0095 : 35.68144\n",
      "0003)  0056 : 35.91369\n",
      "0004)  0099 : 36.11695\n",
      "0005)  0067 : 36.12194\n",
      "0006)  0059 : 36.27812\n",
      "0007)  0064 : 36.30204\n",
      "0008)  0058 : 36.33633\n",
      "0009)  0084 : 36.40311\n",
      "0010)  0092 : 36.47732\n",
      "0011)  0091 : 36.94551\n",
      "0012)  0021 : 36.97743\n",
      "0013)  0034 : 37.13865\n",
      "0014)  0020 : 37.21719\n",
      "0015)  0088 : 37.22053\n",
      "0016)  0074 : 37.22135\n",
      "0017)  0063 : 37.27504\n",
      "0018)  0052 : 37.29624\n",
      "0019)  0041 : 37.33023\n",
      "0020)  0082 : 37.35915\n",
      "0021)  0009 : 37.36345\n",
      "0022)  0001 : 37.37668\n",
      "0023)  0047 : 37.40102\n",
      "0024)  0040 : 37.61327\n",
      "0025)  0065 : 37.66921\n",
      "0026)  0030 : 37.77854\n",
      "0027)  0068 : 37.85270\n",
      "0028)  0073 : 37.99872\n",
      "0029)  0017 : 38.00673\n",
      "0030)  0022 : 38.03760\n",
      "0031)  0019 : 38.05426\n",
      "0032)  0062 : 38.13022\n",
      "0033)  0096 : 38.14237\n",
      "0034)  0075 : 38.19053\n",
      "0035)  0055 : 38.27944\n",
      "0036)  0045 : 38.28216\n",
      "0037)  0042 : 38.31439\n",
      "0038)  0012 : 38.33684\n",
      "0039)  0035 : 38.36490\n",
      "0040)  0013 : 38.41041\n",
      "0041)  0031 : 38.47053\n",
      "0042)  0054 : 38.47804\n",
      "0043)  0049 : 38.51696\n",
      "0044)  0033 : 38.54482\n",
      "0045)  0011 : 38.54543\n",
      "0046)  0015 : 38.62959\n",
      "0047)  0044 : 38.66058\n",
      "0048)  0098 : 38.76417\n",
      "0049)  0016 : 38.77874\n",
      "0050)  0081 : 38.86051\n",
      "0051)  0006 : 38.89132\n",
      "0052)  0080 : 38.97787\n",
      "0053)  0004 : 39.07039\n",
      "0054)  0089 : 39.10589\n",
      "0055)  0003 : 39.11772\n",
      "0056)  0083 : 39.20682\n",
      "0057)  0077 : 39.20961\n",
      "0058)  0097 : 39.25422\n",
      "0059)  0005 : 39.40037\n",
      "0060)  0027 : 39.42297\n",
      "0061)  0014 : 39.43624\n",
      "0062)  0036 : 39.45319\n",
      "0063)  0008 : 39.45989\n",
      "0064)  0079 : 39.48305\n",
      "0065)  0061 : 39.52942\n",
      "0066)  0076 : 39.59400\n",
      "0067)  0085 : 39.66028\n",
      "0068)  0071 : 39.72099\n",
      "0069)  0066 : 39.77529\n",
      "0070)  0090 : 39.79483\n",
      "0071)  0070 : 39.95779\n",
      "0072)  0048 : 39.95888\n",
      "0073)  0023 : 40.01216\n",
      "0074)  0053 : 40.01436\n",
      "0075)  0050 : 40.11758\n",
      "0076)  0028 : 40.21883\n",
      "0077)  0026 : 40.39530\n",
      "0078)  0094 : 40.45563\n",
      "0079)  0029 : 40.47493\n",
      "0080)  0024 : 40.58320\n",
      "0081)  0018 : 40.61178\n",
      "0082)  0046 : 40.70951\n",
      "0083)  0037 : 40.80271\n",
      "0084)  0078 : 40.84589\n",
      "0085)  0069 : 40.85309\n",
      "0086)  0051 : 40.85888\n",
      "0087)  0025 : 40.99329\n",
      "0088)  0032 : 41.01137\n",
      "0089)  0060 : 41.06064\n",
      "0090)  0093 : 41.16835\n",
      "0091)  0007 : 41.26611\n",
      "0092)  0072 : 41.49793\n",
      "0093)  0010 : 41.60496\n",
      "0094)  0002 : 41.99673\n",
      "0095)  0057 : 42.34295\n",
      "0096)  0000 : 42.63382\n",
      "0097)  0038 : 42.70217\n",
      "0098)  0086 : 42.70723\n",
      "0099)  0043 : 42.97726\n"
     ]
    }
   ],
   "source": [
    "import librenderman as rm\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.python.framework import ops\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from IPython.display import Audio\n",
    "\n",
    "midi_note = 40\n",
    "midi_velocity = 127\n",
    "note_length = 0.8\n",
    "render_length = 2.1\n",
    "\n",
    "engine = rm.RenderEngine(44100, 512, 2048)\n",
    "path = \"/home/tollie/Development/vsts/dexed/Builds/Linux/build/Dexed.so\"\n",
    "\n",
    "if engine.load_plugin(path):\n",
    "    generator = rm.PatchGenerator(engine)\n",
    "    print \"Successfully loaded Dexed\"\n",
    "\n",
    "# Function for generating a train, test and validation dataset for both\n",
    "# mfccs and rms frames.\n",
    "def generate_data(midi_note,\n",
    "                  midi_velocity,\n",
    "                  note_length,\n",
    "                  render_length,\n",
    "                  engine,\n",
    "                  generator,\n",
    "                  examples_amount):\n",
    "    examples = []\n",
    "\n",
    "    for i in range(examples_amount):\n",
    "        # A random synthesiser preset in the form of a tuple.\n",
    "        random_patch = generator.get_random_patch()\n",
    "\n",
    "        # Program in the patch on the synth.\n",
    "        engine.set_patch(random_patch)\n",
    "\n",
    "        # Render the latent audio and features that come with such a\n",
    "        # patch.\n",
    "        engine.render_patch(midi_note,\n",
    "                            midi_velocity,\n",
    "                            note_length,\n",
    "                            render_length)\n",
    "\n",
    "        # Get RMS and MFCC frames of audio recorded in render_patch().\n",
    "        mfcc_frames = np.array(engine.get_mfcc_frames())\n",
    "        rms_frames = np.array(engine.get_rms_frames())\n",
    "\n",
    "        # Add this example to the examples list.\n",
    "        examples += [(mfcc_frames, rms_frames, random_patch)]\n",
    "\n",
    "    return examples\n",
    "\n",
    "# Function to normalise each dataset and return a unified dataset of\n",
    "# feature vectors repsectively for the test, train and validation sets.\n",
    "def normalise_data(examples, mfcc_normaliser, rms_normaliser):\n",
    "\n",
    "    # This will hold all of the normalised examples.\n",
    "    normalised_examples = []\n",
    "\n",
    "    # Loop over all the passed in examples.\n",
    "    for i in range(len(examples)):\n",
    "\n",
    "        # Unpack the current example.\n",
    "        mfcc_frames, rms_frames, synth_patch = examples[i]\n",
    "\n",
    "        # Respectively normalise MFCCs and RMS frames.\n",
    "        mfcc_normalised = mfcc_normaliser.transform(mfcc_frames)\n",
    "        rms_normalised = rms_normaliser.transform(rms_frames)\n",
    "\n",
    "        # Repack the now normalised example as a new tuple.\n",
    "        normalised_examples += [(mfcc_normalised,\n",
    "                                 rms_normalised.reshape(-1, 1),\n",
    "                                 synth_patch)]\n",
    "    return normalised_examples\n",
    "\n",
    "# Function to concatenate an examples X data (RMS and MFCC frames) so\n",
    "# they are a joined feature vector.\n",
    "def create_feature_vector_examples(examples):\n",
    "\n",
    "    feature_vector_examples = []\n",
    "\n",
    "    # Looping through the passed in examples.\n",
    "    for example in examples:\n",
    "        mfcc_frames, rms_frames, synth_patch = example\n",
    "\n",
    "        # Each RMS frame and MFCCs Frame is concatenated into a\n",
    "        # respective feature vector.\n",
    "        feature_vector = np.hstack((mfcc_frames, rms_frames))\n",
    "        feature_vector = feature_vector.flatten()\n",
    "        feature_vector_examples += [(feature_vector, synth_patch)]\n",
    "\n",
    "    return feature_vector_examples\n",
    "\n",
    "# Fit a sklearn normaliser respectively for both the audio and mfccs\n",
    "# using a newly generated dataset.\n",
    "\n",
    "# Get enough training examples for the sklearn normaliser so that it can\n",
    "# normalise unseen examples well.\n",
    "print \"\\n\\nStarted generating data for normaliser's fitting, this may take some time...\\n\\n\"\n",
    "fitting_amount = 20\n",
    "fitting_data = generate_data(midi_note,\n",
    "                             midi_velocity,\n",
    "                             note_length,\n",
    "                             render_length,\n",
    "                             engine,\n",
    "                             generator,\n",
    "                             fitting_amount)\n",
    "print \"Finished generating!\\n\\n\"\n",
    "# Take the list of tuples of mfcc and rms arrays and split them into rms\n",
    "# and mfcc arrays.\n",
    "split_data = [np.array(list(t)) for t in zip(*fitting_data)]\n",
    "\n",
    "# Reshape the mfccs so that it is just a 2d stack of mfcc features,\n",
    "# rather than a list of 2d mfcc features for each respective example.\n",
    "fitting_mfccs = split_data[0].reshape(-1, split_data[0].shape[2])\n",
    "fitting_rms = split_data[1]\n",
    "\n",
    "mfcc_normaliser = preprocessing.Normalizer().fit(fitting_mfccs)\n",
    "rms_normaliser = preprocessing.Normalizer().fit(fitting_rms)\n",
    "print \"Finished fitting!\\n\\n\"\n",
    "\n",
    "def remove_patch_indices(examples):\n",
    "    no_index_examples = []\n",
    "\n",
    "    for example in examples:\n",
    "        _, __, synth_patch = example\n",
    "        no_indices_patch = np.array([p[1] for p in synth_patch])\n",
    "        no_index_examples += [(_, __, no_indices_patch)]\n",
    "    return no_index_examples\n",
    "\n",
    "def add_patch_indices(patch_without_indices):\n",
    "    patch_with_indices = []\n",
    "    for i, parameter in enumerate(patch_without_indices):\n",
    "        patch_with_indices += [(i, float(parameter))]\n",
    "    return patch_with_indices\n",
    "\n",
    "\n",
    "\n",
    "def generate_examples(amount,\n",
    "                      midi_note,\n",
    "                      midi_velocity,\n",
    "                      note_length,\n",
    "                      render_length,\n",
    "                      engine,\n",
    "                      generator,\n",
    "                      mfcc_normaliser,\n",
    "                      rms_normaliser):\n",
    "\n",
    "    examples = generate_data(midi_note,\n",
    "                             midi_velocity,\n",
    "                             note_length,\n",
    "                             render_length,\n",
    "                             engine,\n",
    "                             generator,\n",
    "                             amount)\n",
    "    examples = remove_patch_indices(examples)\n",
    "    normalised_examples = normalise_data(examples,\n",
    "                                         mfcc_normaliser,\n",
    "                                         rms_normaliser)\n",
    "    return create_feature_vector_examples(normalised_examples)\n",
    "\n",
    "# Create the tensorflow graph.\n",
    "dimension_data_example = generate_examples(1,\n",
    "                                           midi_note,\n",
    "                                           midi_velocity,\n",
    "                                           note_length,\n",
    "                                           render_length,\n",
    "                                           engine,\n",
    "                                           generator,\n",
    "                                           mfcc_normaliser,\n",
    "                                           rms_normaliser)\n",
    "\n",
    "features, parameters = dimension_data_example[0]\n",
    "# https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3_NeuralNetworks/recurrent_network.ipynb\n",
    "# Parameters for the tensorflow graph.\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "number_hidden_1 = 200\n",
    "number_hidden_2 = 175\n",
    "number_hidden_3 = 150\n",
    "\n",
    "# Network parameters:\n",
    "# 14 * 181 - (amount of mfccs + rms value) * sample size\n",
    "number_input = int(features.shape[0])\n",
    "\n",
    "# 155 - amount of parameters\n",
    "number_outputs = len(parameters)\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, number_input], name=\"Features\")\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases, prob_keep_input, prob_keep_hidden):\n",
    "    # Hidden layer with RELU activation\n",
    "    with tf.name_scope(\"Layer_1\"):\n",
    "        layer_1 = tf.nn.dropout(x, prob_keep_input)\n",
    "        layer_1 = tf.add(tf.matmul(layer_1, weights['h1']), biases['b1'])\n",
    "        layer_1 = tf.nn.relu(layer_1)\n",
    "\n",
    "    # Hidden layer with RELU activation\n",
    "    with tf.name_scope(\"Layer_2\"):\n",
    "        layer_2 = tf.nn.dropout(layer_1, prob_keep_hidden)\n",
    "        layer_2 = tf.add(tf.matmul(layer_2, weights['h2']), biases['b2'])\n",
    "        layer_2 = tf.nn.relu(layer_2)\n",
    "\n",
    "    # Hidden layer with RELU activation\n",
    "    with tf.name_scope(\"Layer_3\"):\n",
    "        layer_3 = tf.nn.dropout(layer_2, prob_keep_hidden)\n",
    "        layer_3 = tf.add(tf.matmul(layer_3, weights['h3']), biases['b3'])\n",
    "        layer_3 = tf.nn.relu(layer_3)\n",
    "\n",
    "    # Output layer with linear activation\n",
    "    with tf.name_scope(\"Output\"):\n",
    "        out_layer = tf.nn.dropout(layer_3, prob_keep_hidden)\n",
    "        out_layer = tf.add(tf.matmul(out_layer, weights['out']), biases['out'])\n",
    "        return out_layer\n",
    "\n",
    "def init_weights(shape, name):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01), name=name)\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': init_weights([number_input, number_hidden_1], \"Weights_Hidden_1\"),\n",
    "    'h2': init_weights([number_hidden_1, number_hidden_2], \"Weights_Hidden_2\"),\n",
    "    'h3': init_weights([number_hidden_2, number_hidden_3], \"Weights_Hidden_3\"),\n",
    "    'out': init_weights([number_hidden_3, number_outputs], \"Weights_Out\")\n",
    "}\n",
    "biases = {\n",
    "    'b1': init_weights([number_hidden_1], \"Biases_1\"),\n",
    "    'b2': init_weights([number_hidden_2], \"Biases_2\"),\n",
    "    'b3': init_weights([number_hidden_3], \"Biases_3\"),\n",
    "    'out': init_weights([number_outputs], \"Biases_Out\")\n",
    "}\n",
    "\n",
    "tf.summary.histogram(\"Weights_1_Summary\", weights['h1'])\n",
    "tf.summary.histogram(\"Weights_2_Summary\", weights['h2'])\n",
    "tf.summary.histogram(\"Weights_3_Summary\", weights['h3'])\n",
    "tf.summary.histogram(\"Weights Out\", weights['out'])\n",
    "\n",
    "prob_keep_input = tf.placeholder(\"float\", name=\"Probability_Keep_Input\")\n",
    "prob_keep_hidden = tf.placeholder(\"float\", name=\"Probability_Keep_Hidden\")\n",
    "\n",
    "# Construct model\n",
    "prediction = multilayer_perceptron(x,\n",
    "                                   weights,\n",
    "                                   biases,\n",
    "                                   prob_keep_input,\n",
    "                                   prob_keep_hidden)\n",
    "\n",
    "# Add ops to save and restore all variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Launching the graph.\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "\n",
    "        # Restore variables from disk.\n",
    "        saver.restore(sess, \"models/model.ckpt\")\n",
    "        print(\"Model restored.\")\n",
    "\n",
    "        test_batch = generate_examples(batch_size,\n",
    "                                       midi_note,\n",
    "                                       midi_velocity,\n",
    "                                       note_length,\n",
    "                                       render_length,\n",
    "                                       engine,\n",
    "                                       generator,\n",
    "                                       mfcc_normaliser,\n",
    "                                       rms_normaliser)\n",
    "\n",
    "        split_train = map(list, zip(*test_batch))\n",
    "        batch_x = split_train[0]\n",
    "        batch_y = split_train[1]\n",
    "\n",
    "        pred = sess.run([prediction], feed_dict={ x: batch_x,\n",
    "                                                  prob_keep_input: 1.0,\n",
    "                                                  prob_keep_hidden: 1.0 })\n",
    "\n",
    "        all_tests = []\n",
    "\n",
    "        for i in range(len(pred[0])):\n",
    "            total_abs = 0\n",
    "\n",
    "            for param in range(len(pred[0][0])):\n",
    "                total_abs += abs(pred[0][i][param] - batch_y[i][param])\n",
    "\n",
    "            absolute_distance_table = \" \" +(\"%04d\" % i) + \" : \" + (\"%.5f\" % round(total_abs, 5))\n",
    "            all_tests.append((total_abs, absolute_distance_table, pred[0][i], batch_y[i]))\n",
    "\n",
    "        all_tests.sort(key=lambda x: x[0])\n",
    "\n",
    "        print \"\\n\\n      In order of most to least similar predictions compared to the actual parameters:\\n\\n      Index   Total abs\"\n",
    "        print \"       _______________\"\n",
    "        for i in range(len(all_tests)):\n",
    "            print (\"%04d\" % i) + \") \" + all_tests[i][1]\n",
    "\n",
    "        for i in range(1):\n",
    "            patch_predicted = add_patch_indices(all_tests[i][2])\n",
    "            patch_actual = add_patch_indices(all_tests[i][3])\n",
    "\n",
    "            engine.set_patch(patch_predicted)\n",
    "            engine.render_patch(midi_note,\n",
    "                                midi_velocity,\n",
    "                                note_length,\n",
    "                                render_length)\n",
    "            file_name = str(i) + \"_pred.wav\"\n",
    "            pred_audio = engine.get_audio_frames()\n",
    "            Audio(pred_audio, rate=44100)\n",
    "\n",
    "            engine.set_patch(patch_actual)\n",
    "            engine.render_patch(midi_note,\n",
    "                                midi_velocity,\n",
    "                                note_length,\n",
    "                                render_length)\n",
    "            file_name = str(i) + \"_actual.wav\"\n",
    "            actual_audio = engine.get_audio_frames()\n",
    "            Audio(actual_audio, rate=44100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
